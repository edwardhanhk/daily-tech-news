import os
import feedparser
from datetime import datetime, timezone
from xml.etree.ElementTree import Element, SubElement, tostring
import xml.dom.minidom

def get_hn_entries():
    """è·å– Hacker News æ¡ç›®"""
    try:
        rss = feedparser.parse('https://hnrss.org/frontpage')
        entries = []
        for entry in rss.entries[:5]:
            entries.append({
                'title': f"[HN] {entry.title}",
                'link': entry.link,
                'published': entry.published,
                'summary': ''
            })
        return entries
    except Exception as e:
        print(f"âš ï¸ HN æŠ“å–å¤±è´¥: {e}")
        return []

def get_reddit_entries(subreddit="technology"):
    """è·å– Reddit æ¡ç›®"""
    try:
        rss = feedparser.parse(f'https://www.reddit.com/r/{subreddit}/top.rss?t=day')
        entries = []
        for entry in rss.entries[:5]:
            title = entry.title.split(': ')[-1] if ': ' in entry.title else entry.title
            entries.append({
                'title': f"[r/{subreddit}] {title}",
                'link': entry.link,
                'published': entry.published,
                'summary': entry.summary if hasattr(entry, 'summary') else ''
            })
        return entries
    except Exception as e:
        print(f"âš ï¸ Reddit æŠ“å–å¤±è´¥: {e}")
        return []

def create_rss_feed(entries):
    """ç”Ÿæˆæ ‡å‡† RSS XML"""
    # åˆ›å»ºæ ¹å…ƒç´ 
    rss = Element('rss', {'version': '2.0'})
    channel = SubElement(rss, 'channel')
    
    # é¢‘é“ä¿¡æ¯
    SubElement(channel, 'title').text = 'æ¯æ—¥ç§‘æŠ€çƒ­å¸–'
    SubElement(channel, 'link').text = 'https://github.com/edwardhanhk/daily-tech-news'
    SubElement(channel, 'description').text = 'æ¯æ—¥è‡ªåŠ¨æŠ“å– Hacker News å’Œ Reddit ç§‘æŠ€çƒ­å¸–'
    SubElement(channel, 'lastBuildDate').text = datetime.now(timezone.utc).strftime('%a, %d %b %Y %H:%M:%S %z')
    SubElement(channel, 'generator').text = 'GitHub Actions + Python'

    # æ·»åŠ æ¡ç›®
    for item_data in entries:
        item = SubElement(channel, 'item')
        SubElement(item, 'title').text = item_data['title']
        SubElement(item, 'link').text = item_data['link']
        SubElement(item, 'guid', {'isPermaLink': 'true'}).text = item_data['link']
        SubElement(item, 'pubDate').text = item_data['published']
        if item_data['summary']:
            SubElement(item, 'description').text = item_data['summary']

    # æ ¼å¼åŒ– XML
    rough_string = tostring(rss, 'unicode')
    reparsed = xml.dom.minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ")

def save_rss_file(content, filename='feed.xml'):
    """ä¿å­˜ RSS æ–‡ä»¶åˆ° docs ç›®å½•ï¼ˆGitHub Pages é»˜è®¤ç›®å½•ï¼‰"""
    os.makedirs('docs', exist_ok=True)
    with open(f'docs/{filename}', 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"âœ… RSS æ–‡ä»¶å·²ä¿å­˜: docs/{filename}")

if __name__ == "__main__":
    print("ğŸ“¡ å¼€å§‹ç”Ÿæˆ RSS è®¢é˜…æº...")
    
    # è·å–æ‰€æœ‰æ¡ç›®
    hn_items = get_hn_entries()
    reddit_items = get_reddit_entries("technology")
    all_items = hn_items + reddit_items
    
    # æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    all_items.sort(key=lambda x: x['published'], reverse=True)
    
    # ç”Ÿæˆå¹¶ä¿å­˜ RSS
    rss_content = create_rss_feed(all_items)
    save_rss_file(rss_content)
